{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60e984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "from scipy import spatial, stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from adjustText import adjust_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f479d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = '/mnt/data0/lucy/manosphere/'\n",
    "DATA = ROOT + 'data/'\n",
    "GLOVE = DATA + 'glove/'\n",
    "LOGS = ROOT + 'logs/'\n",
    "AGG_EMBED_PATH = LOGS + 'semantics_mano/agg_embed/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ebbe86",
   "metadata": {},
   "source": [
    "## Inspecting individual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bc5624",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(LOGS + 'semantics_mano/results/scores.json', 'r') as infile: \n",
    "    scores = json.load(infile) \n",
    "\n",
    "vocab_order = []\n",
    "with open(LOGS + 'semantics_mano/results/vocab_order.txt', 'r') as infile:\n",
    "    vocab_order = infile.readlines()\n",
    "\n",
    "with open(LOGS + 'coref_results/mano_gender_labels.json', 'r') as infile: \n",
    "    gender_labels = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1077b631",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_poles = defaultdict(Counter) # {word : {pole : score}}\n",
    "for pole in scores: \n",
    "    s = scores[pole]\n",
    "    for i, term in enumerate(vocab_order): \n",
    "        term = term.strip()\n",
    "        word_poles[term][pole] = s[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fe6a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_poles['alpha'].most_common()[:10])\n",
    "print(word_poles['alpha'].most_common()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90207e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_poles['beta'].most_common()[:10])\n",
    "print(word_poles['beta'].most_common()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd19b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_poles['escort'].most_common()[:10])\n",
    "print(word_poles['escort'].most_common()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8ac883",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_poles['wife'].most_common()[:10])\n",
    "print(word_poles['wife'].most_common()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2b259c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_poles['celebrities'].most_common()[:10])\n",
    "print(word_poles['celebrities'].most_common()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12650b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_poles['princes'].most_common()[:10])\n",
    "print(word_poles['princes'].most_common()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fc1685",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_poles['normies'].most_common()[:10])\n",
    "print(word_poles['normies'].most_common()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1329a1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_poles['simps'].most_common()[:10])\n",
    "print(word_poles['simps'].most_common()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd39c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_poles['prostitute'].most_common()[:10])\n",
    "print(word_poles['prostitute'].most_common()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58870ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_poles['sweet girl'].most_common()[:10])\n",
    "print(word_poles['sweet girl'].most_common()[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a106bfe7",
   "metadata": {},
   "source": [
    "# Variance within gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468fc95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fem_variance = Counter() # {pole: variance of fem terms}\n",
    "fem_extremes = defaultdict(tuple) # {pole: (top N terms, bottom N terms)}\n",
    "masc_variance = Counter() \n",
    "masc_extremes = defaultdict(tuple)\n",
    "fem_scores = defaultdict(list) # {pole: scores in order of x_words}\n",
    "masc_scores = defaultdict(list) # {pole: scores in order of y_words}\n",
    "N = 10\n",
    "for pole in scores: \n",
    "    s = scores[pole]\n",
    "    x = [] # fem scores\n",
    "    x_words = []\n",
    "    y = [] # masc scores\n",
    "    y_words = []\n",
    "    for i, term in enumerate(vocab_order): \n",
    "        term = term.strip()\n",
    "        if term in gender_labels: \n",
    "            if gender_labels[term] > 0.75: \n",
    "                x.append(s[i])\n",
    "                x_words.append(term)\n",
    "            elif gender_labels[term] < 0.25: \n",
    "                y.append(s[i])\n",
    "                y_words.append(term)\n",
    "    fem_variance[pole] = np.var(x)\n",
    "    indices = np.argpartition(x, -N)[-N:]\n",
    "    topN = [x_words[idx].strip() for idx in indices]\n",
    "    indices = np.argpartition(x, N)[:N]\n",
    "    bottomN = [x_words[idx].strip() for idx in indices]\n",
    "    fem_extremes[pole] = (topN, bottomN, min(x), max(x))\n",
    "    fem_scores[pole] = x\n",
    "    \n",
    "    masc_variance[pole] = np.var(y)\n",
    "    indices = np.argpartition(y, -N)[-N:]\n",
    "    topN = [y_words[idx].strip() for idx in indices]\n",
    "    indices = np.argpartition(y, N)[:N]\n",
    "    bottomN = [y_words[idx].strip() for idx in indices]\n",
    "    masc_extremes[pole] = (topN, bottomN, min(y), max(y))\n",
    "    masc_scores[pole] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb754145",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tup in fem_variance.most_common(20): \n",
    "    print(tup)\n",
    "    pole = tup[0]\n",
    "    topN, bottomN, mi, ma = fem_extremes[pole]\n",
    "    print(\"TOP:\", topN)\n",
    "    print(\"BOTTOM:\", bottomN)\n",
    "    print(mi, ma)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436e41ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tup in masc_variance.most_common(20): \n",
    "    print(tup)\n",
    "    pole = tup[0]\n",
    "    topN, bottomN, mi, ma = masc_extremes[pole]\n",
    "    print(\"TOP:\", topN)\n",
    "    print(\"BOTTOM:\", bottomN)\n",
    "    print(mi, ma)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff5c12d",
   "metadata": {},
   "source": [
    "## Axes similarities for each clusters' highly gendered terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eff724",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(LOGS + 'gram_counts/combined_catyear_word_count.json', 'r') as infile: \n",
    "    catyear_word_count = json.load(infile)\n",
    "total_vocab_count = Counter() # {term : count in mano reddit + forum}\n",
    "for catyear in catyear_word_count: \n",
    "    for term in catyear_word_count[catyear]: \n",
    "        total_vocab_count[term] += catyear_word_count[catyear][term]\n",
    "print(total_vocab_count.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efc2ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(LOGS + 'time_series/cluster_members_6.json', 'r') as infile: \n",
    "    clust_words = json.load(infile)\n",
    "clust_words_rev = {}\n",
    "for clust in clust_words: \n",
    "    cluster_words = clust_words[clust]\n",
    "    for w in cluster_words: \n",
    "        clust_words_rev[w] = clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deac4d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_gender_sum = defaultdict(Counter) # {gender + clust_num : {pole : sum of word scores} }\n",
    "cluster_gender_total = defaultdict(Counter) # {gender + clust_num : {pole : word count} }\n",
    "for pole in scores: \n",
    "    s = scores[pole]\n",
    "    for i, term in enumerate(vocab_order): \n",
    "        term = term.strip()\n",
    "        clust_num = clust_words_rev[term]\n",
    "        if term in gender_labels: \n",
    "            if gender_labels[term] > 0.75: \n",
    "                cluster_gender_sum[str(clust_num) + '_fem'][pole] += s[i]\n",
    "                cluster_gender_total[str(clust_num) + '_fem'][pole] += 1\n",
    "            elif gender_labels[term] < 0.25: \n",
    "                cluster_gender_sum[str(clust_num) + '_masc'][pole] += s[i]\n",
    "                cluster_gender_total[str(clust_num) + '_masc'][pole] += 1\n",
    "            else: \n",
    "                cluster_gender_sum[str(clust_num) + '_other'][pole] += s[i]\n",
    "                cluster_gender_total[str(clust_num) + '_other'][pole] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e786bd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_gender_avg = defaultdict(Counter) \n",
    "for key in cluster_gender_sum: \n",
    "    for pole in cluster_gender_sum[key]: \n",
    "        if key.endswith('fem'): \n",
    "            pole_avg = np.mean(fem_scores[pole])\n",
    "        elif key.endswith('masc'): \n",
    "            pole_avg = np.mean(masc_scores[pole])\n",
    "        else: \n",
    "            continue\n",
    "#         pole_avg = np.mean(scores[pole])\n",
    "        cluster_gender_avg[key][pole] = cluster_gender_sum[key][pole] / cluster_gender_total[key][pole] - pole_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f13500",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_order = [4, 3, 5, 1, 2, 0]\n",
    "for clust_num in cluster_order: \n",
    "    for gender in ['fem', 'masc']:\n",
    "        key = str(clust_num) + '_' + gender\n",
    "        print(key)\n",
    "        print(cluster_gender_avg[key].most_common()[:10])\n",
    "        print(cluster_gender_avg[key].most_common()[-10:])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbf53e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
